# hyperparams for training seq2seq SMILES spellchecking model

path_to_datafile_train: 'data/SMILES/smiles.raw.train300k'
path_to_datafile_test: 'data/SMILES/smiles.raw.test10k'
path_to_smiles_dict: 'data/SMILES/Dictionary'
mode: 'seq2seq'
rn_in_input: True
smiles_one_hot: False

model: 'seq2seq'
hidden_size: 512
embd_size: 64
cell_type: 'LSTM'
num_layers: 2
start_teacher_forcing_p: 1.0
teacher_forcing_decay: 0.99
max_smiles_len: 60
smiles_dict_size: 58
encoder_dropout_p: 0.2
decoder_dropout_p: 0.2

path_to_save_model: 'seqtoseq/seqtoseq_rn_64emb.pth'
save_model_every: 50


batch_size: 128
l_r: 0.01
decay_lr_every: 500
gamma: 0.1
num_epochs: 200

